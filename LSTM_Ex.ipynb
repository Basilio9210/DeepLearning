{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ex_LSTM.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"6jtWAEoaTJSc","colab_type":"text"},"cell_type":"markdown","source":["# Long - Short Term Memory Networks\n","\n","![texto alternativo](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)"]},{"metadata":{"id":"Ey4LxaeDZVz4","colab_type":"text"},"cell_type":"markdown","source":["# **Setup Example**\n","\n","Create a simple Word prediction LSTM. It takes a fairytale (or story) from a text file to analyze words as sequences, in order to predict next word based on previous ones. The main purpose of the model is taking several initial words and provide a story based on words learnt during training stage."]},{"metadata":{"id":"isD_CTlzcr99","colab_type":"code","outputId":"7bb35614-41c5-449a-f2b5-90980d56ae83","executionInfo":{"status":"ok","timestamp":1542665542668,"user_tz":300,"elapsed":10216,"user":{"displayName":"Ruben Fonnegra","photoUrl":"","userId":"00076635575783849948"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["'''\n","A Long - Short Term Memory Networks (LSTM) implementation using TensorFlow..\n","A prediction of a word after n_input words learned from text file.\n","A story is automatically generated if some initial words are provided to\n","feed the model as input. \n","'''\n","\n","\n","from google.colab import drive\n","#drive.mount(\"/content/data/\")\n","!ls data/'My Drive'/'Colab Notebooks'/'Datasets'/'LSTM_words'/\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.contrib import rnn\n","from tensorflow.nn import rnn_cell\n","import random\n","import collections\n","import time"],"execution_count":0,"outputs":[{"output_type":"stream","text":["belling_the_cat.txt\n"],"name":"stdout"}]},{"metadata":{"id":"hdWbi-SJeStf","colab_type":"code","outputId":"fc28d0c0-bf1c-4aec-9d66-c48945d206cd","executionInfo":{"status":"ok","timestamp":1542665542673,"user_tz":300,"elapsed":10174,"user":{"displayName":"Ruben Fonnegra","photoUrl":"","userId":"00076635575783849948"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["start_time = time.time()\n","\n","# Define a log file to sum up our model\n","# Conveniently, the log will be stored in our data path \n","data_path = \"data/My Drive/Colab Notebooks/Datasets/LSTM_words/\"\n","#writer = tf.summary.FileWriter(data_path)\n","\n","# Text file containing words for training\n","training_file = 'belling_the_cat.txt'\n","\n","# Reading text file\n","def read_data(fname):\n","    with open(fname) as f:\n","        content = f.readlines()\n","    content = [x.strip() for x in content]\n","    content = [word for i in range(len(content)) for word in content[i].split()]\n","    content = np.array(content)\n","    return content\n","\n","training_data = read_data(data_path+training_file)\n","print(\"Training data loaded...\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training data loaded...\n"],"name":"stdout"}]},{"metadata":{"id":"XlO3SjGsezRY","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_dataset(words):\n","    count = collections.Counter(words).most_common()\n","    dictionary = dict()\n","    for word, _ in count:\n","        dictionary[word] = len(dictionary)\n","    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n","    return dictionary, reverse_dictionary\n","\n","dictionary, reverse_dictionary = build_dataset(training_data)\n","vocab_size = len(dictionary)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GEigp5Z8narI","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Define parameters\n","learning_rate = 0.001\n","n_input = 3\n","num_epochs = 20000\n","num_classes = 2\n","echo_step = 500\n","#echo_step = 1000\n","batch_size = 5\n","words_to_predict = 10\n","\n","\n","# number of units in RNN cell\n","n_hidden = 512\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tc3IeorpsPu4","colab_type":"code","outputId":"e9284320-2615-4e8a-ec9f-d90f57fea932","executionInfo":{"status":"error","timestamp":1542665542707,"user_tz":300,"elapsed":10195,"user":{"displayName":"Ruben Fonnegra","photoUrl":"","userId":"00076635575783849948"}},"colab":{"base_uri":"https://localhost:8080/","height":1276}},"cell_type":"code","source":["\n","# --- Create placeholders\n","batchX_placeholder = tf.placeholder(tf.float32, [None, _ , 1])\n","batchY_placeholder = tf.placeholder(tf.float32, [None, vocab_size])\n","\n","init_state = tf.placeholder(tf.float32, [batch_size, vocab_size])\n","\n","# --- Weights, Bias initialization\n","W = tf.Variable(np.random.rand( _ , vocab_size), dtype=tf.float32)\n","b = tf.Variable(np.zeros((1, _ )), dtype=tf.float32)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    946\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-63769bc4843f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatchX_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatchY_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minit_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   5202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5203\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5204\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5205\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5206\u001b[0m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n\u001b[0;32m--> 146\u001b[0;31m                                                                     e))\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error converting shape to a TensorShape: invalid literal for int() with base 10: ''."]}]},{"metadata":{"id":"egANUoZ8SUzk","colab_type":"text"},"cell_type":"markdown","source":["Training considering previous states.\n","\n","![texto alternativo](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"]},{"metadata":{"id":"1zgjV9TMKQon","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://deeplearning4j.org/img/greff_lstm_diagram.png)"]},{"metadata":{"id":"d7HqFLD8sPl2","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def model(input_placeholder, weights, biases):\n","    \n","    # reshape to [1, n_input]\n","    input_placeholder = tf.reshape(input_placeholder, [-1, _ ])\n","    \n","    # Generate a n_input-element sequence of inputs\n","    # (eg. [had] [a] [general] -> [20] [6] [33])\n","    input_placeholder = tf.split(input_placeholder, n_input,1)\n","    \n","    # 1-layer LSTM with n_hidden units but with lower accuracy.\n","    # Average Accuracy= 90.60% 50k iter\n","    cell = rnn_cell.LSTMCell (n_hidden, reuse=tf.AUTO_REUSE)\n","    \n","    # 2-layer LSTM, each layer has n_hidden units.\n","    # Average Accuracy= 95.20% at 50k iter\n","    # cell = rnn.MultiRNNCell([rnn_cell.LSTMCell(n_hidden), rnn_cell.LSTMCell(n_hidden)])\n","    \n","    # generate prediction\n","    outputs, states = rnn.static_rnn(cell, input_placeholder, dtype=tf.float32)\n","    \n","    # there are n_input outputs but\n","    # we only want the last output\n","    return _ \n","\n","predictions = model(batchX_placeholder, W, b)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z-gX4DT6Y5Oo","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Loss and optimizer\n","total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = _ , labels= _ ))\n","optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(total_loss)\n","\n","# Model evaluation\n","# Introduce the accuracy estimation based on predictions\n","correct_predictions = tf.equal(tf.argmax( _ ,1), tf.argmax( _ ,1))\n","accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n","\n","# Initializing the variables\n","init = tf.global_variables_initializer()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tZQRXU9yW4iZ","colab_type":"text"},"cell_type":"markdown","source":["To realize predictions, we will extract the prediction probabilities for number in a sequence of words. The idea lays in achieve good prediction in the words according to the initial story.\n","\n","\n","![texto alternativo](https://cdn-images-1.medium.com/max/800/1*XAJdt_EbedqDlrTT9eqWvQ.png)"]},{"metadata":{"id":"KqmhpOehw129","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Launch the graph\n","with tf.Session() as session:\n","    session.run(init)\n","    step = 0\n","    offset = random.randint(0,n_input+1)\n","    end_offset = n_input + 1\n","    acc_total = 0\n","    loss_list = 0\n","\n","    #writer.add_graph(session.graph)\n","\n","    # while step < training_iters:\n","    for epoch_idx in range(num_epochs): #\n","        # Generate a minibatch. Add some randomness on selection process.\n","        if offset > (len(training_data)-end_offset):\n","            offset = random.randint(0, n_input+1)\n","        \n","        # Define the input words per batch\n","        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n","        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n","        \n","        # Define the label of words per batch\n","        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n","        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n","        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n","        \n","        # Feed the graph\n","        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, total_loss, predictions], \\\n","                                                feed_dict={batchX_placeholder: _ , \\\n","                                                           batchY_placeholder: _ })\n","        loss_list += loss\n","        acc_total += acc\n","        if (epoch_idx+1) % echo_step == 0:\n","            \n","            print(\"Step = \" + str(epoch_idx+1) + \", Loss = \" + \\\n","                  \"{:.6f}\".format(loss_list/echo_step) + \", Accuracy= \" + \\\n","                  \"{:.2f}%\".format(100 * acc_total / echo_step))\n","            acc_total = 0\n","            loss_list = 0\n","            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n","            symbols_out = training_data[offset + n_input]\n","            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n","            print(\"%s - [%s] vs [%s]\" % (symbols_in, symbols_out, symbols_out_pred))\n","        #step += 1\n","        offset += (n_input+1)\n","    \n","    print(\"Optimization Finished!\")\n","    \n","    \n","    flag = True\n","    while flag == True:\n","        prompt = \"Write %s words: \" % n_input\n","        sentence = input(prompt)\n","        sentence = sentence.strip()\n","        words = sentence.split(' ')\n","        \n","        if words[0] == '1':\n","            flag = False\n","            break\n","        \n","        if len(words) != n_input:\n","            print (\"Wrong num of words\")\n","            continue\n","        try:\n","        #if True:\n","            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n","            for i in range(words_to_predict):\n","                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n","                onehot_pred = session.run(predictions, feed_dict={batchX_placeholder: keys})\n","                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n","                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n","                symbols_in_keys = symbols_in_keys[1:]\n","                symbols_in_keys.append(onehot_pred_index)\n","            print(sentence)\n","            \n","        except:\n","        #else:\n","            print(\"Word not in dictionary\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zKV4GYRhLQfc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"QwrpDE7vLXhx","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]} 